{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forward_and_backward_propagation_for_one_hidden_layer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFOianUmqoWj"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIg1AWPIdQ1X"
      },
      "source": [
        "def ReLU(X):\n",
        "   return np.maximum(0,X)\n",
        "\n",
        "def sigmoid(X):\n",
        "   return 1/(1+np.exp(-X))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIvPmdzvCMX"
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    X -- input data of size (n_x, m)\n",
        "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
        "    \n",
        "    Returns:\n",
        "    A2 -- The sigmoid output of the second activation\n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
        "    \"\"\"\n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2  =parameters['b2']\n",
        " \n",
        "    \n",
        "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
        "\n",
        "    Z1 = np.dot(W1,X) + b1\n",
        "    A1 = ReLU(Z1)\n",
        "    Z2 = np.dot(W2,A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "    \n",
        "    assert(A2.shape == (1, X.shape[1]))\n",
        "    \n",
        "    cache = {\"Z1\": Z1,\n",
        "             \"A1\": A1,\n",
        "             \"Z2\": Z2,\n",
        "             \"A2\": A2}\n",
        "    \n",
        "    return A2, cache"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3bKZT85ZhY5"
      },
      "source": [
        "def backward_propagation(parameters, cache, X, Y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing our parameters \n",
        "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
        "    X -- input data of shape (2, number of examples)\n",
        "    Y -- \"true\" labels vector of shape (1, number of examples)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- python dictionary containing your gradients with respect to different parameters\n",
        "    \"\"\"\n",
        "    m = X.shape[1]\n",
        "    \n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "\n",
        "        \n",
        "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
        "  \n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    A1 = cache['A1']\n",
        "    \n",
        "\n",
        "    \n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
        "    \n",
        "    dZ2 = A2 - Y\n",
        "    dW2 = np.dot(dZ2,A1.T)/m;\n",
        "    db2 = np.sum(dZ2,axis=1,keepdims=True)/m\n",
        "    dZ1 = np.dot(W2.T,dZ2)*(1-np.power(A1,2))\n",
        "    dW1 = np.dot(dZ1,X.T)/m\n",
        "    db1 = np.sum(dZ1,axis=1,keepdims=True)/m\n",
        "   \n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2}\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}